# Based_on_host

## Project Structure & Scripts

###  Data Processing & Feature Extraction

| Script | Description |
|--------|-------------|
| `generate_esm2_embedding.py` | Extracts 1280-dim ESM-2 embeddings from FASTA input, saves as `.npy` |
| `check_fasta_embedding_order.py` | Ensures that `.fasta` and `.npy` sequence orders match; outputs `*_ids.txt` |

---

###  Model Training & Inference

| Script | Description |
|--------|-------------|
| `train_mlp_focal.py` | Trains MLP with Focal Loss and EarlyStopping; saves model as `best_model.pt` |
| `predict_on_hx.py` | Loads model and `.npy` data to predict host-binding labels for new subtypes |

---

## Model Details

- **Input:** 1280-dim ESM-2 embeddings (no structural or host metadata)
- **Architecture:** MLP with hidden layers: 1280 → 128 → 32 → 2 (binary classification)
- **Loss:** Focal Loss
- **Validation:** EarlyStopping + weighted sampling
- **Output:** `best_model.pt`

---

## H1/H3 Training Performance

| Metric | Value |
|--------|-------|
| Accuracy | 99.63% |
| AUC | 0.999 |
| Confusion Matrix | Perfect separation of human vs. avian |
| Model Output | `best_model.pt` |

---

##  Generalization Performance (H5 / H7 / H9)

| Subtype | Accuracy | Recall (class 1) | Precision (class 1) | Observations |
|---------|----------|------------------|----------------------|--------------|
| **H5** | 18.5% |  1.0000 |  0.0608 | Severe overfitting toward positive class |
| **H7** | 47.3% |  0.0020 |  1.0000 | Fails to recognize human-adapted sequences |
| **H9** | 97.1% |  0.0000 |  0.0000 | Biased accuracy due to class imbalance (avian dominant) |

 Confusion matrices saved as:

- `confusion_matrix_H5.png`
- `confusion_matrix_H7.png`
- `confusion_matrix_H9.png`

---

##  Current Issues

1. **Overfitting to H1/H3 domain** — poor cross-subtype generalization
2. **Severe class imbalance** — especially in H5/H7/H9 (few human isolates)
3. **No structural context** — ESM-2 captures sequence semantics only
4. **No subtype-specific tuning** — zero-shot on H5/H7/H9

---

##  Next Steps

| Area | Strategy |
|------|----------|
|  Structural Features | Incorporate RSA, residue-distance features to enhance context |
|  Cross-Subtype Fine-tuning | Introduce few-shot labeled samples from H5/7/9 |
|  Architecture Enhancement | Explore attention-based MLP or domain adaptation |
|  Class Imbalance | Use Focal Loss, sampling strategies, or label smoothing |
|  Domain Visualization | Apply t-SNE/UMAP to visualize subtype distribution in embedding space |

---

##  Sample Output Files

- `train_sequences.npy`, `train_labels.npy`
- `test_sequences.npy`, `test_labels.npy`
- `H5_predictions.csv`, `H5_metadata_with_label.csv`
- `confusion_matrix_H5.png`, etc.

---

##  Reproducibility Notes

- Ensure sequence and `.npy` embedding alignment via `check_fasta_embedding_order.py`
- All predictions rely on `.npy` files generated by `generate_esm2_embedding.py`
- Model training logs and metrics are stored in standard stdout

---


